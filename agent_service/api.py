import os
import json
import datetime
from typing import Dict, Any

# --- Importa√ß√µes do FastAPI e Pydantic ---
from fastapi import FastAPI
from pydantic import BaseModel, Field

# --- Importa√ß√µes do Firebase ---
import firebase_admin
from firebase_admin import credentials
from firebase_admin import firestore

# --- Importa√ß√µes do Gemini API ---
from google import genai
from google.genai import types

# --- Configura√ß√£o do LLM ---
try:
    if os.environ.get("GEMINI_API_KEY"):
        LLM_CLIENT = genai.Client()
        print("ü§ñ Cliente Gemini API inicializado.")
    else:
        LLM_CLIENT = None
        print("‚ö†Ô∏è Vari√°vel GEMINI_API_KEY n√£o encontrada. Usando simula√ß√£o antiga.")
except Exception as e:
    print(f"‚ùå Erro ao inicializar o Cliente Gemini: {e}")
    LLM_CLIENT = None

# --- Configura√ß√£o do Firebase ---
try:
    cred = credentials.ApplicationDefault()
    firebase_admin.initialize_app(cred)
    db = firestore.client()
    print("üöÄ Firebase e Firestore inicializados com sucesso.")
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao inicializar o Firebase: {e}")
    db = None

app = FastAPI(title="Customer Feedback AI Agent")

# --- Modelos Pydantic ---
class FeedbackRequest(BaseModel):
    text: str

class FeedbackResponse(BaseModel):
    # CORRE√á√ÉO APLICADA: model_config foi removido para evitar ValidationError.
    
    category: str = Field(description="Classifique em uma destas op√ß√µes: 'Log√≠stica', 'Bug no App', 'Sugest√£o', 'Atendimento' ou 'Geral'.")
    sentiment: str = Field(description="Classifique em 'Positivo', 'Neutro' ou 'Negativo'.")
    summary: str = Field(description="Uma breve descri√ß√£o da a√ß√£o necess√°ria (se for Negativo) ou o ponto positivo (se for Positivo).")

# --- Fun√ß√£o de Fallback (L√≥gica Antiga de Keywords) ---
def simular_processamento_antigo(text: str) -> FeedbackResponse:
    """ Usa a l√≥gica de keywords como fallback. """
    text_lower = text.lower()
    
    # L√≥gica de Classifica√ß√£o (Simulada)
    if "atrasou" in text_lower or "chegou tarde" in text_lower or "log√≠stica" in text_lower:
        ml_category = "Log√≠stica"
    elif "travou" in text_lower or "bug" in text_lower or "pix" in text_lower:
        ml_category = "Bug no App"
    elif "sugest√£o" in text_lower or "adicionar" in text_lower:
        ml_category = "Sugest√£o"
    else:
        ml_category = "Geral / Outros"

    # L√≥gica de Sentimento (Simulada)
    if "rude" in text_lower or "atrasou" in text_lower or "fria" in text_lower or "errada" in text_lower or "sumiu" in text_lower:
        sentiment = "Negativo"
        summary = "Cliente insatisfeito. Problemas identificados: " + ml_category + ". Requer aten√ß√£o imediata da equipe respons√°vel."
    
    elif "gentil" in text_lower or "quente" in text_lower or "5 estrelas" in text_lower or "impec√°vel" in text_lower or "adorei" in text_lower:
        sentiment = "Positivo"
        summary = "Cliente muito satisfeito! Feedback positivo sobre " + ml_category + ". Oportunidade para incentivar boas pr√°ticas."
    
    else:
        sentiment = "Neutro"
        summary = "O feedback n√£o cont√©m palavras-chave cr√≠ticas. Classificado como " + ml_category + " para an√°lise de produto."
        
    return FeedbackResponse(
        category=ml_category,
        sentiment=sentiment,
        summary=summary
    )

# --- Fun√ß√£o para Salvar no Firestore ---
def save_to_firestore(data: Dict[str, Any]):
    """ Salva os dados de feedback processados na cole√ß√£o 'feedback_history' do Firestore. """
    if db:
        try:
            data['timestamp'] = datetime.datetime.now(tz=datetime.timezone.utc)
            db.collection('feedback_history').add(data)
            print(f"‚úÖ Feedback salvo no Firestore: {data.get('category')} / {data.get('sentiment')}")
        except Exception as e:
            print(f"‚ùå Erro ao salvar no Firestore: {e}")
    else:
        print("‚ùå Firestore n√£o inicializado. N√£o foi poss√≠vel salvar o feedback.")

# --- Endpoint Principal (com LLM) ---
@app.post("/process", response_model=FeedbackResponse)
def process_feedback(request: FeedbackRequest):
    """
    Endpoint que envia o feedback para o LLM (Gemini 2.5 Flash)
    para classifica√ß√£o estruturada e salva no Firestore.
    """
    text = request.text
    
    if LLM_CLIENT is None:
        print("‚ö†Ô∏è Usando Fallback. LLM_CLIENT √© None.")
        return simular_processamento_antigo(text)

    # --- 1. PROMPT ENGINEERING e CONFIGURA√á√ÉO ---
    prompt = f"Analise o texto do cliente e retorne o objeto JSON com base no esquema fornecido. TEXTO: '{text}'"

    # CORRE√á√ÉO APLICADA: Limpando o esquema JSON para evitar o erro de valida√ß√£o (extra_forbidden)
    response_schema = types.Schema(json_schema=FeedbackResponse.model_json_schema(by_alias=True, exclude_none=True))
    
    config = types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=response_schema
    )

    # --- 2. CHAMADA AO LLM ---
    try:
        response = LLM_CLIENT.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=config
        )
        
        # O LLM retorna uma string JSON. Parseamos e validamos com Pydantic.
        llm_json_string = response.text.strip()
        llm_output_data = json.loads(llm_json_string)
        
        # Valida√ß√£o do Pydantic garante que o LLM respondeu no formato correto
        response_data = FeedbackResponse(**llm_output_data)

    except Exception as e:
        print(f"‚ùå Erro na chamada do LLM: {e}")
        # Retorna uma resposta de erro estruturada
        response_data = FeedbackResponse(
             category="Erro de LLM", 
             sentiment="Neutro", 
             summary=f"Falha na API Gemini: {str(e)}"
        )

    # --- 3. SALVAR NO FIRESTORE ---
    firestore_data = response_data.model_dump()
    firestore_data["raw_text"] = text
    save_to_firestore(firestore_data)
        
    return response_data

@app.get("/")
def health_check():
    return {"status": "Agente Ativo üöÄ"}